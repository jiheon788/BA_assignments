{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e6aeab8-be8a-40dd-9468-942607fc752c",
   "metadata": {},
   "source": [
    "# HW5_한글문서 분류\n",
    "## 201823871 박지헌\n",
    "  \n",
    "  \n",
    "## 0. 데이터 전처리\n",
    "### 0.1 데이터 불러오기\n",
    "**Data: movie_data.csv**    \n",
    "'신과함께', '코코', '라라랜드', '인피니티 워', '곤지암' 다섯개의 영화에 대해 총 1827개의 리뷰를 수집 csv 파일 안에 리뷰내용, 평점, 영화이름 의 순으로 저장되어 있음\n",
    "\n",
    "|  | review | rate | name |\n",
    "|--|--------|------|------|\n",
    "| index | .. | .. | .. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e237456-2788-4326-856b-cb82e9efe358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['혹시', '나', '하고', '봤는데', '역시', '나다', ';;', '편집', '과', '사운드', '로', '주는', '작은', '공포', '영화', \"'\", '푸시', \"'\", '에서', '인상', '깊게', '봤던걸', '여기', '서', '또', '보네', ';;']\n"
     ]
    }
   ],
   "source": [
    "print(twitter_tag.morphs(X_train[1])) #둘째 리뷰에 대해 형태소 단위로 tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b8e3cce-b188-442f-a7a2-606d099b049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2876ac94-eb80-419a-82f8-94cb5e32536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "text = []\n",
    "y = []\n",
    "with open('movie_data.csv', encoding='utf-8') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    for row in csvreader:\n",
    "        #print(row)\n",
    "        if row: #그 줄에 내용이 있는 경우에만\n",
    "            text.append(row[0]) #영화 리뷰를 text 리스트에 추가\n",
    "            y.append(row[2]) #영화이름을 text 리스트에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25c70c57-13f3-4115-9695-61be2e75cbc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of samples: 1827\n",
      "Movie titles of reivews: {'코코', '라라랜드', '곤지암', '인피니티 워', '신과함께'}\n"
     ]
    }
   ],
   "source": [
    "print('Num of samples: {}'.format(len(text)))\n",
    "print('Movie titles of reivews: {}'.format(set(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0116da-602e-4c52-a3b7-5fa3d062ba4e",
   "metadata": {},
   "source": [
    "### 0.2 데이터 스플릿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef577132-0b06-4fca-8811-cedeb5b627e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, y, random_state=0)\n",
    "# 비율을 지정하지 않으면 75:25로 분할됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "51a65fd5-8584-4144-b0c1-a682a3023eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1370"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train) #1827의 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a45d310-d5f9-4108-9e19-021300cb268a",
   "metadata": {},
   "source": [
    "## 1. 모델 학습\n",
    "### 1.1 Model 1 - 명사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9753897a-48a8-4b19-894d-72c2c3770e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt #konlpy에서 Twitter 형태소 분석기를 import\n",
    "#from konlpy.tag import Twitter #konlpy에서 Twitter 형태소 분석기를 import\n",
    "twitter_tag = Okt()\n",
    "#twitter_tag = Twitter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b278721-4356-4834-ba23-5518266b2254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['혹시', '나', '하고', '봤는데', '역시', '나다', ';;', '편집', '과', '사운드', '로', '주는', '작은', '공포', '영화', \"'\", '푸시', \"'\", '에서', '인상', '깊게', '봤던걸', '여기', '서', '또', '보네', ';;']\n"
     ]
    }
   ],
   "source": [
    "print(twitter_tag.morphs(X_train[1])) #둘째 리뷰에 대해 형태소 단위로 tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d52667f5-510f-48c7-b1dd-682a7f044383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['혹시', '역시', '편집', '사운드', '공포', '영화', '푸시', '인상', '여기', '또']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_tag.nouns(X_train[1]) #둘째 리뷰에서 명사만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "12ad76ea-d9e1-40ca-9946-b440308956e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twit_tokenizer(text): # Twitter 형태소 분석기의 명사추출함수를 tokenizer 함수로 사용\n",
    "    return twitter_tag.nouns(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2856ade9-910c-4e33-bf9d-a76eff578fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.8364963503649635\n",
      "Test score 0.6717724288840262\n",
      "(1370, 1156)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=2) #Twitter 형태소분석기에서 명사만 추출하는 함수를 tokenizer로 이용\n",
    "# twit_tokenizer 대신 twitter_tag.nouns를 직접 써도 됨\n",
    "# 하나의 문서에서만 출현한 단어는 쓸모가 없으므로 제외, 즉 최소 document frequency를 2로 설정\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train) # train data 변환 -> tfidf vector\n",
    "X_test_tfidf = tfidf.transform(X_test) # test data 변환 -> tfidf vector\n",
    "\n",
    "clf = LogisticRegression() # logistic regression 분류기 선언\n",
    "clf.fit(X_train_tfidf, y_train) # 분류기 학습\n",
    "print('Train score', clf.score(X_train_tfidf, y_train)) # train data 예측정확도\n",
    "print('Test score', clf.score(X_test_tfidf, y_test)) # test data 예측정확도\n",
    "print(X_train_tfidf.shape) # 총 1156개의 명사로 이루어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ac6fbdc6-42f9-4abb-be2e-f76697b0d5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['졸잼 최고',\n",
       " '내용, 음악 , 연기력  무엇하나 빠지는것이 없네요 특히 음악은 계속 찾아 듣게되요^^',\n",
       " '아맥2D로 느즈막히 관람.... 히어로가 많이나오지만, 이걸 꽤나 잘 버무려놓음. 뻔한스토리의 틀을 벗어나려 노력한점은 높은점수를 줄만함.... 블럭버스터액션, 영상미는 말이필요없음...... 후속편 기대됨!',\n",
       " '후반부터 쫄렸다.',\n",
       " '진짜. 솔직히 한국 공포영화중에 이렇게 소재별로인건 정말 오랜만인듯; 지들끼리 소리지르고 정신없이 우왕자왕 심지어 무섭지도않어 효과음만크고 진짜최악임ㅉㅉ',\n",
       " '소문난 잔치에 먹을거 없음..ㅜㅜ',\n",
       " 'good!',\n",
       " '아 점수를 줄 수가 없네  화면은 왜그리도 흔들어 데는지........ 재미도 없고 가볍기만하고 .... 최악의 재미없는 배멀미 영화',\n",
       " '영화 보면서 펑펑물었네요~ 부모님 사랑에 대해 다시한번 생각하게 했던 영화네요^ ^',\n",
       " '슬픈 스토리지만 삶을 돌아보게 하는 영화다. 죄를 지은자는 그 벌을 고스란히 받으리라. 사회 각종범죄자들 뉘우치길 바란다.']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:10] #test data에서 앞 10개를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ab8cbd7-97ac-4850-a8a0-bc09aa8257f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['인피니티 워', '라라랜드', '인피니티 워', '곤지암', '곤지암', '인피니티 워', '인피니티 워',\n",
       "       '신과함께', '코코', '신과함께'], dtype='<U6')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test_tfidf[:10]) # test data의 앞 10개에 대한 예측내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5cc9958c-6ef7-4792-bb23-5784b69e6b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['인피니티 워', '라라랜드', '인피니티 워', '곤지암', '곤지암', '인피니티 워', '인피니티 워', '곤지암', '신과함께', '신과함께']\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:10]) # test data 앞 10개의 실제 영화제목"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0770c030-9784-49c1-9a06-a48b3068299e",
   "metadata": {},
   "source": [
    "|  | 정확도 | \n",
    "|--|--------|\n",
    "| Train score | **0.83** |\n",
    "| Test score | **0.67** |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3386e1dd-faa4-427b-bc39-42e545047b71",
   "metadata": {},
   "source": [
    "### 1.2 Model 2 - 모든 형태소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67a28255-2b9c-434c-8b8e-a816704e3ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['혹시', '나', '하고', '봤는데', '역시', '나다', ';;', '편집', '과', '사운드', '로', '주는', '작은', '공포', '영화', \"'\", '푸시', \"'\", '에서', '인상', '깊게', '봤던걸', '여기', '서', '또', '보네', ';;']\n"
     ]
    }
   ],
   "source": [
    "# morphs()는 명사 외에도 모든 형태소를 포함\n",
    "print(twitter_tag.morphs(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "469d265d-f163-45bc-97ef-561544fcd0f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.8963503649635036\n",
      "Test score 0.649890590809628\n",
      "(1370, 2260)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twitter_tag.morphs, min_df=2) # 명사 대신 모든 형태소를 사용\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)\n",
    "#명사만 사용한 것에 비해 train score는 상승, test score는 하락"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7da9c50-dbfd-46d4-947b-b2f045d8db1c",
   "metadata": {},
   "source": [
    "|  | 정확도 | \n",
    "|--|--------|\n",
    "| Train score | **0.89** |\n",
    "| Test score | **0.64** |  \n",
    "\n",
    "  \n",
    "명사만 사용한 것에 비해 train score는 상승, test score는 하락\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5f8d99aa-028e-4e68-9a1c-a9d2f7548bb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('혹시', 'Noun'), ('나', 'Josa'), ('하다', 'Verb'), ('보다', 'Verb'), ('역시', 'Noun'), ('나다', 'Verb'), (';;', 'Punctuation'), ('편집', 'Noun'), ('과', 'Josa'), ('사운드', 'Noun'), ('로', 'Josa'), ('주다', 'Verb'), ('작다', 'Adjective'), ('공포', 'Noun'), ('영화', 'Noun'), (\"'\", 'Punctuation'), ('푸시', 'Noun'), (\"'\", 'Punctuation'), ('에서', 'Josa'), ('인상', 'Noun'), ('깊다', 'Adjective'), ('보다', 'Verb'), ('여기', 'Noun'), ('서', 'Josa'), ('또', 'Noun'), ('보다', 'Verb'), (';;', 'Punctuation')]\n"
     ]
    }
   ],
   "source": [
    "print(twitter_tag.pos(X_train[1], norm=True, stem=True)) #pos()는 형태소와 품사를 함께 제공"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf149826-09f7-40b4-a2dd-cee759640324",
   "metadata": {},
   "source": [
    "### 1.3 Model 3 - 명사, 동사, 형용사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "661a456c-9682-47c7-896a-43ed2bb9ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def twit_tokenizer2(text): #전체를 다 사용하는 대신, 명사, 동사, 형용사를 사용\n",
    "    target_tags = ['Noun', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in twitter_tag.pos(text, norm=True, stem=True):\n",
    "        if tag in target_tags:\n",
    "            result.append(word)\n",
    "#            result.append('/'.join([word, tag]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4c7983f6-b70a-4441-8bb2-ce503454e70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['혹시', '하다', '보다', '역시', '나다', '편집', '사운드', '주다', '작다', '공포', '영화', '푸시', '인상', '깊다', '보다', '여기', '또', '보다']\n"
     ]
    }
   ],
   "source": [
    "print(twit_tokenizer2(X_train[1])) # 사용 예"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7162d922-cae5-4d9e-9a36-fdd3813582a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.8715328467153285\n",
      "Test score 0.6849015317286652\n",
      "(1370, 1584)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer2, min_df=2) #명사, 동사, 형용사를 이용하여 tfidf 생성\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)\n",
    "# 현재까지 중에서 test score가 가장 뛰어남"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e395b0bd-7bc6-45a6-a67b-43d8e64b2901",
   "metadata": {},
   "source": [
    "|  | 정확도 | \n",
    "|--|--------|\n",
    "| Train score | **0.87** |\n",
    "| Test score | **0.68** |  \n",
    "\n",
    " 현재까지 중에서 test score가 가장 뛰어남\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98f5dda-7449-42ec-922c-6ea5ea0c4f1a",
   "metadata": {},
   "source": [
    "### 1.4 Model 4 - 모든 형태소, 품사를 알 수 있도록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c3a5051-9f26-44af-a7c5-5abc0099fc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 형태소를 다 사용하고 품사를 알 수 있도록 하면?\n",
    "def twit_tokenizer3(text):\n",
    "    #target_tags = ['Noun', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in twitter_tag.pos(text, norm=True, stem=True):\n",
    "        result.append('/'.join([word, tag])) #단어의 품사를 구분할 수 있도록 함\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f5fc537c-a469-464a-ab58-a5799b1dc107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.8927007299270073\n",
      "Test score 0.6739606126914661\n",
      "(1370, 2023)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer3, min_df=2)\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)\n",
    "#성능이 오히려 떨어지고 품사 표시 없이 전체를 다 사용한 경우에 비해 train은 떨어지고, test는 올라감"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f76fe4d-d3cf-4d17-9e22-23ec7937151d",
   "metadata": {},
   "source": [
    "|  | 정확도 | \n",
    "|--|--------|\n",
    "| Train score | **0.89** |\n",
    "| Test score | **0.66** |  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab37a40-d76f-4ec9-b53e-c9265f707ddf",
   "metadata": {},
   "source": [
    "### 1.5 Model 5 - ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a921a25c-2f89-4088-981d-c8dc2b2a5945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.944\n",
      "Test set score: 0.676\n"
     ]
    }
   ],
   "source": [
    "# train score가 높으므로 ridge를 쓰면 어떨까?\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "ridge_clf = RidgeClassifier(alpha = 1)\n",
    "ridge_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n",
    "# train score가 올라가는 현상이 벌어짐\n",
    "# test score가 올라갔으나 명사, 형용사, 동사를 쓴 것보다 떨어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8900eb63-3882-42ea-aa8c-dd32cd242d08",
   "metadata": {},
   "source": [
    "|  | 정확도 | \n",
    "|--|--------|\n",
    "| Train score | **0.94** |\n",
    "| Test score | **0.67** |  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e03f5ed-c2bf-4581-8218-f94b84a1dc3e",
   "metadata": {},
   "source": [
    "### 1.6 Model 6 - Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "598dc608-bb84-46c4-8bd6-4d1b12d6a14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.718\n",
      "Test set score: 0.643\n",
      "Used features count: 240 out of 2023\n"
     ]
    }
   ],
   "source": [
    "#lasso를 쓰면?\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "lasso_clf = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "lasso_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train set score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))\n",
    "print('Used features count: {}'.format(np.sum(lasso_clf.coef_ != 0)), 'out of', X_train_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e744f7-4f9e-486e-877f-d0b1c6d73109",
   "metadata": {},
   "source": [
    "|  | 정확도 | \n",
    "|--|--------|\n",
    "| Train score | **0.71** |\n",
    "| Test score | **0.64** |  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b621dc40-5e0f-41c4-8a11-d0d13d229068",
   "metadata": {},
   "source": [
    "### 1.7 Model 7 - Lsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d729afa7-5807-43e4-8d98-0aca4d5b1caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01102934 0.01405529 0.01144551 0.0110093  0.00918016 0.00876149\n",
      " 0.00836851 0.00795922 0.00777003 0.00737423 0.00707199 0.00665546\n",
      " 0.00659729 0.00616382 0.00588976 0.00563969 0.00546929 0.00543044\n",
      " 0.00524396 0.00523751 0.0051354  0.00507564 0.00494917 0.00478661\n",
      " 0.00466253 0.0046021  0.00455272 0.00452943 0.00432636 0.0043043\n",
      " 0.00425346 0.00416261 0.00410043 0.00401296 0.00399825 0.00396182\n",
      " 0.00392779 0.00385998 0.00373325 0.00369469 0.00365484 0.00363113\n",
      " 0.00357832 0.00354544 0.00349848 0.00346928 0.00337552 0.00334918\n",
      " 0.00332458 0.00330956 0.00323571 0.00321667 0.00315217 0.00314053\n",
      " 0.00309441 0.00307477 0.0030649  0.00301359 0.00300256 0.00296081\n",
      " 0.00293836 0.00291433 0.00288938 0.00288701 0.00286437 0.00281526\n",
      " 0.00280011 0.00276482 0.00274032 0.00271676 0.00269105 0.00266254\n",
      " 0.00264105 0.00262961 0.00260318 0.00258836 0.00257263 0.0025549\n",
      " 0.00253862 0.00252722 0.00251281 0.00248844 0.00248194 0.00245121\n",
      " 0.00244755 0.00241116 0.00239864 0.0023803  0.00236743 0.00235925\n",
      " 0.00232777 0.00231998 0.00228583 0.00225879 0.00224278 0.00222963\n",
      " 0.00222807 0.00219394 0.00218403 0.00217777 0.00216885 0.00213963\n",
      " 0.00213221 0.00211726 0.0021082  0.00208491 0.00207873 0.00206984\n",
      " 0.0020442  0.00203715 0.00203109 0.00202247 0.00200684 0.00199728\n",
      " 0.00198139 0.00197578 0.00196858 0.0019567  0.00195046 0.00193928\n",
      " 0.00192188 0.00191527 0.00190398 0.00190288 0.00189315 0.00188382\n",
      " 0.00186635 0.00185401 0.00184764 0.00184161 0.0018402  0.00182065\n",
      " 0.001813   0.00179631 0.00179194 0.00178155 0.00177619 0.00177247\n",
      " 0.00176391 0.00174575 0.00174084 0.00173493 0.00172713 0.00172038\n",
      " 0.00171324 0.00169736 0.00169107 0.00168815 0.00167718 0.00166958\n",
      " 0.0016606  0.00165005 0.00164831 0.00163445 0.00162676 0.00162542\n",
      " 0.00161713 0.00161272 0.00159771 0.00159238 0.00159037 0.00158957\n",
      " 0.00156833 0.00156387 0.00155943 0.00155314 0.00154517 0.00154178\n",
      " 0.00153878 0.00153156 0.00152027 0.00151681 0.00150908 0.00150907\n",
      " 0.00150429 0.00148962 0.00148561 0.00147865 0.00147801 0.00146682\n",
      " 0.00146001 0.00145723 0.00144468 0.00143961 0.00143002 0.00142921\n",
      " 0.0014208  0.00141638 0.00141579 0.00140818 0.0014034  0.00139324\n",
      " 0.00139056 0.00138567 0.00137493 0.00137155 0.00136727 0.00135985\n",
      " 0.00135444 0.00134977 0.00134562 0.00133558 0.00133122 0.00132535\n",
      " 0.00132194 0.00131758 0.00131066 0.00130911 0.00130505 0.00129728\n",
      " 0.00129571 0.00128405 0.00127616 0.00127324 0.00126559 0.00125941\n",
      " 0.00125722 0.00125095 0.00124375 0.00124088 0.00123686 0.00123166\n",
      " 0.00122136 0.00121416 0.00120729 0.00119822 0.00119425 0.0011902\n",
      " 0.00118219 0.00117517 0.00117452 0.0011669  0.00115835 0.00114922\n",
      " 0.00114639 0.00113962 0.00113862 0.00113157 0.00112449]\n",
      "\n",
      "\n",
      "0.627470454928045\n",
      "\n",
      "\n",
      "[7.18722998 4.37716265 3.87707769 3.80401495 3.46987465 3.38992696\n",
      " 3.31319188 3.23081401 3.19295868 3.11176267 3.0479269  2.97464527\n",
      " 2.94181282 2.84376785 2.7792728  2.72052017 2.67818072 2.66871722\n",
      " 2.62671166 2.6211839  2.59772293 2.58190277 2.54773577 2.50549056\n",
      " 2.47514125 2.46249764 2.44458218 2.44081919 2.38195771 2.37595715\n",
      " 2.36213857 2.33646299 2.31897222 2.29462272 2.28988032 2.27951064\n",
      " 2.2696032  2.25224959 2.21275983 2.20157946 2.18941753 2.18229454\n",
      " 2.16700863 2.15629757 2.14384191 2.13417342 2.10461423 2.09580568\n",
      " 2.08809633 2.08457671 2.06118326 2.05524985 2.03983521 2.02947381\n",
      " 2.0156339  2.00808902 2.00484508 1.98892489 1.9848698  1.97080544\n",
      " 1.96433732 1.95685115 1.94851579 1.94618356 1.93878407 1.92354149\n",
      " 1.91631125 1.90417728 1.8957369  1.88786307 1.8786183  1.86911358\n",
      " 1.86110158 1.85717919 1.84914318 1.84466386 1.83680751 1.83047136\n",
      " 1.8257132  1.82052779 1.81602147 1.80661829 1.80431053 1.79331989\n",
      " 1.79183982 1.77843174 1.77363887 1.76688172 1.76225481 1.75901716\n",
      " 1.7472136  1.74547341 1.73138953 1.72112568 1.71500666 1.71000327\n",
      " 1.70948057 1.69627556 1.69249592 1.69011496 1.68727252 1.67602962\n",
      " 1.67226219 1.66647038 1.66276613 1.65396201 1.65116958 1.64756305\n",
      " 1.63885047 1.6351727  1.63216299 1.62859852 1.62272231 1.6199386\n",
      " 1.61197651 1.60973638 1.60686067 1.6019874  1.59937235 1.59485625\n",
      " 1.58767203 1.58485923 1.58104529 1.57976164 1.57568875 1.57192692\n",
      " 1.56637507 1.55945183 1.55681473 1.55449401 1.55349754 1.54521608\n",
      " 1.54228311 1.53494218 1.53323466 1.52873209 1.52685008 1.52467317\n",
      " 1.52095301 1.51360868 1.51136655 1.50844406 1.50501843 1.50295063\n",
      " 1.4990343  1.49203042 1.48921439 1.48844592 1.48323386 1.47971939\n",
      " 1.47588973 1.47125412 1.47030967 1.46441287 1.46089164 1.4600098\n",
      " 1.45645421 1.45430045 1.44757356 1.4451948  1.44418574 1.44381833\n",
      " 1.43474477 1.43241517 1.43075667 1.42734688 1.4239681  1.42213184\n",
      " 1.42056782 1.41722678 1.4129636  1.41085354 1.40692287 1.40682537\n",
      " 1.40490821 1.39769447 1.39580527 1.39275219 1.3922484  1.38695654\n",
      " 1.38382998 1.38275183 1.37645068 1.37404564 1.36964869 1.36905779\n",
      " 1.36514341 1.36291003 1.36262579 1.35901456 1.35666126 1.35220907\n",
      " 1.35071654 1.34873489 1.34301621 1.34134439 1.33943739 1.33542613\n",
      " 1.33276808 1.33056349 1.3284238  1.32349714 1.32147413 1.31838175\n",
      " 1.31677435 1.31457724 1.31126584 1.31041624 1.30838878 1.30434815\n",
      " 1.30356031 1.29770436 1.29424264 1.29220091 1.28853219 1.28520775\n",
      " 1.2841347  1.28089417 1.27725376 1.27569374 1.27362989 1.27093976\n",
      " 1.26565419 1.26203966 1.25829658 1.25355624 1.25168127 1.24946418\n",
      " 1.24542796 1.24144044 1.24113263 1.23706028 1.2325742  1.22773662\n",
      " 1.22629484 1.22251701 1.22209418 1.21818685 1.21495199]\n",
      "\n",
      "\n",
      "(239, 2023)\n"
     ]
    }
   ],
   "source": [
    "#lsa를 쓰면?\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=239, n_iter=7, random_state=42) #압축할 component의 수 지정\n",
    "svd.fit(X_train_tfidf)  \n",
    "print(svd.explained_variance_ratio_)  #계산된 각 component가 설명하는 분산의 비율\n",
    "print('\\n')\n",
    "print(svd.explained_variance_ratio_.sum())  #선택된 component들이 설명하는 분산의 합 -> 선택한 component의 수에 따라 달라짐\n",
    "print('\\n')\n",
    "print(svd.singular_values_) \n",
    "print('\\n')\n",
    "print(svd.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "49400657-875e-439d-b28a-3349bee3fc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set score: 0.771\n",
      "Test set score: 0.654\n"
     ]
    }
   ],
   "source": [
    "X_train_svd = svd.transform(X_train_tfidf) #선택된 component를 이용하여 2,000개의 feature로부터 feature extract (dimension reduce)\n",
    "X_test_svd = svd.transform(X_test_tfidf)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "SVD_clf = LogisticRegression()\n",
    "SVD_clf.fit(X_train_svd, y_train)\n",
    "print('Train set score: {:.3f}'.format(SVD_clf.score(X_train_svd, y_train)))\n",
    "print('Test set score: {:.3f}'.format(SVD_clf.score(X_test_svd, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1008e8-e28f-4942-82b2-31d08bc791fb",
   "metadata": {},
   "source": [
    "|  | 정확도 | \n",
    "|--|--------|\n",
    "| Train score | **0.77** |\n",
    "| Test score | **0.65** |  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735ed4aa-809e-420a-9ece-d7d2ed8013e2",
   "metadata": {},
   "source": [
    "### 1.8 Model 8 - max_feature를 제한하여 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "149a885e-c441-471e-9b83-4173ce7c9b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82104\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:489: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set dimension: (1370, 1584)\n",
      "Test set dimension: (457, 1584)\n",
      "Train set score: 0.801\n",
      "Test set score: 0.685\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(tokenizer=twit_tokenizer2, min_df=2).fit(X_train) #tfidf와 동일하게 max_feature를 제한하여 학습\n",
    "X_train_cv = cv.transform(X_train) # train set을 변환\n",
    "print('Train set dimension:', X_train_cv.shape) # 36310 대신 2000이 된 것을 확인\n",
    "X_test_cv = cv.transform(X_test) # test set을 변환\n",
    "print('Test set dimension:', X_test_cv.shape)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB_clf = MultinomialNB()\n",
    "NB_clf.fit(X_train_cv, y_train)\n",
    "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_cv, y_train)))\n",
    "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_cv, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d6977c6-0bd5-419a-96a3-da35abb75299",
   "metadata": {},
   "source": [
    "|  | 정확도 | \n",
    "|--|--------|\n",
    "| Train score | **0.80** |\n",
    "| Test score | **0.68** |  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d757c2-1d81-494a-986a-506d26840d15",
   "metadata": {},
   "source": [
    "### 1.9 최종선정\n",
    "\n",
    "|  | Model1 | Mode2 | Model3 | Model4 | Mode5 | Model6 | Model7 | Model8 |\n",
    "|--|--------|-------|--------|--------|-------|--------|--------|--------|\n",
    "| Train Score | 0.83 | 0.89 | **0.87** | 0.89 | 0.94 | 0.71 | 0.77 | 0.80 |\n",
    "| Test Score | 0.67 | 0.64 | **0.68** | 0.66 | 0.67 | 0.64 | 0.65 | 0.68 |\n",
    "  \n",
    "> Test에서 가장 높은 정확도를 가진 모델 중, 가장 높은 Train 정확도를 가진 **Model 3** 채택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb28d032-c3d6-4c7e-a6fe-f304265995af",
   "metadata": {},
   "source": [
    "## 2. 활용 - 네이버 영화리뷰에 적용\n",
    "### 2.1 영화 리뷰 크롤링\n",
    "\n",
    "1. 네 가지 영화의 네이버 리뷰를 400개씩 크롤링 하여 1600개의 데이터가 담긴 데이터프레임 생성\n",
    "    * 보이스\n",
    "    * 이터널스\n",
    "    * 듄\n",
    "    * 베놈2  \n",
    "2. 데이터 통합\n",
    "\n",
    "3. Model 3에 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "21a67329-c459-4d56-b712-87d1b9b38962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 11_2_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.114 Safari/537.36',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "50140599-0522-4be7-bd96-8022d0d863d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>안 그래도 짱깨 싫은데 더 싫어짐 보이스피싱,미세먼지,코로나,알몸 김치 얘네는 존재...</td>\n",
       "      <td>보이스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>이렇게 자세하게 묘사될줄은 몰라서 보이스피싱 단계? 마다 긴장하면서 본듯ㅋㅋ 전개가...</td>\n",
       "      <td>보이스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>보는내내 기분 더럽다보이스피싱하는새끼들 뒤봐주는새끼들싹다 사형하는  법 내면 김일성...</td>\n",
       "      <td>보이스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>많이들 보시고 보이스피싱 안당하셨으면 ㅈ좋겠네요!!</td>\n",
       "      <td>보이스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>배우들의 명연기가 압권이고, 주연조연 모두 맡은 배역이 찰떡!!개인적으로 김무열의 ...</td>\n",
       "      <td>보이스</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>1은 별로라는 평 사이에서도 재밌게 봤는데 이건 기대를 안 했는데도 그것보다 더 이...</td>\n",
       "      <td>베놈2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>베놈1 재밌게 봤고, 2는 살짝 비슷한 느낌이었지만 그럼에도 마블은 꼭 보게 되는 ...</td>\n",
       "      <td>베놈2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>베놈과 에디의 신혼일기</td>\n",
       "      <td>베놈2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>쿠키때문에 어쩔수없이 봄.1편보다 액션도 떨어지고 전체적으로 아쉬움</td>\n",
       "      <td>베놈2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>베놈이랑 에디의 결혼식 기대합니다</td>\n",
       "      <td>베놈2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review name\n",
       "0    안 그래도 짱깨 싫은데 더 싫어짐 보이스피싱,미세먼지,코로나,알몸 김치 얘네는 존재...  보이스\n",
       "1    이렇게 자세하게 묘사될줄은 몰라서 보이스피싱 단계? 마다 긴장하면서 본듯ㅋㅋ 전개가...  보이스\n",
       "2    보는내내 기분 더럽다보이스피싱하는새끼들 뒤봐주는새끼들싹다 사형하는  법 내면 김일성...  보이스\n",
       "3                         많이들 보시고 보이스피싱 안당하셨으면 ㅈ좋겠네요!!  보이스\n",
       "4    배우들의 명연기가 압권이고, 주연조연 모두 맡은 배역이 찰떡!!개인적으로 김무열의 ...  보이스\n",
       "..                                                 ...  ...\n",
       "395  1은 별로라는 평 사이에서도 재밌게 봤는데 이건 기대를 안 했는데도 그것보다 더 이...  베놈2\n",
       "396  베놈1 재밌게 봤고, 2는 살짝 비슷한 느낌이었지만 그럼에도 마블은 꼭 보게 되는 ...  베놈2\n",
       "397                                       베놈과 에디의 신혼일기  베놈2\n",
       "398              쿠키때문에 어쩔수없이 봄.1편보다 액션도 떨어지고 전체적으로 아쉬움  베놈2\n",
       "399                                 베놈이랑 에디의 결혼식 기대합니다  베놈2\n",
       "\n",
       "[1600 rows x 2 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## movie_list = [190320,184311,191559,187323]\n",
    "## 보이스 \n",
    "review_list = []\n",
    "\n",
    "# 시작 페이지 지정\n",
    "page_num = 1\n",
    "\n",
    "while True:\n",
    "    # HTML 코드 받아오기\n",
    "    response = requests.get(\"https://movie.naver.com/movie/bi/mi/pointWriteFormList.naver?code=190320&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=\" + str(page_num),headers = headers)\n",
    "\n",
    "    # BeautifulSoup 타입으로 변형하기\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    for i in range(10):\n",
    "        review = soup.find('span',{'id':f'_filtered_ment_{i}'})\n",
    "        review = review.get_text().strip()\n",
    "        review_list.append(review) \n",
    "    #print(str(page_num) + \"번째 페이지 가져오기 완료\")\n",
    "    page_num += 1\n",
    "\n",
    "    if page_num == 41:\n",
    "            break\n",
    "\n",
    "# DataFrame 만들기\n",
    "df1 = pd.DataFrame(data = review_list, columns = ['review'])\n",
    "df1['name'] = '보이스'\n",
    "\n",
    "## 이터널스\n",
    "review_list = []\n",
    "\n",
    "# 시작 페이지 지정\n",
    "page_num = 1\n",
    "\n",
    "while True:\n",
    "    # HTML 코드 받아오기\n",
    "    response = requests.get(\"https://movie.naver.com/movie/bi/mi/pointWriteFormList.naver?code=184311&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=\" + str(page_num),headers = headers)\n",
    "\n",
    "    # BeautifulSoup 타입으로 변형하기\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    for i in range(10):\n",
    "        review = soup.find('span',{'id':f'_filtered_ment_{i}'})\n",
    "        review = review.get_text().strip()\n",
    "        review_list.append(review) \n",
    "    #print(str(page_num) + \"번째 페이지 가져오기 완료\")\n",
    "    page_num += 1\n",
    "\n",
    "    if page_num == 41:\n",
    "            break\n",
    "\n",
    "# DataFrame 만들기\n",
    "df2 = pd.DataFrame(data = review_list, columns = ['review'])\n",
    "df2['name'] = '이터널스'\n",
    "\n",
    "## 듄\n",
    "review_list = []\n",
    "\n",
    "# 시작 페이지 지정\n",
    "page_num = 1\n",
    "\n",
    "while True:\n",
    "    # HTML 코드 받아오기\n",
    "    response = requests.get(\"https://movie.naver.com/movie/bi/mi/pointWriteFormList.naver?code=191559&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=\" + str(page_num),headers = headers)\n",
    "\n",
    "    # BeautifulSoup 타입으로 변형하기\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    for i in range(10):\n",
    "        review = soup.find('span',{'id':f'_filtered_ment_{i}'})\n",
    "        review = review.get_text().strip()\n",
    "        review_list.append(review) \n",
    "    #print(str(page_num) + \"번째 페이지 가져오기 완료\")\n",
    "    page_num += 1\n",
    "\n",
    "    if page_num == 41:\n",
    "            break\n",
    "\n",
    "# DataFrame 만들기\n",
    "df3 = pd.DataFrame(data = review_list, columns = ['review'])\n",
    "df3['name'] = '듄'\n",
    "\n",
    "## 베놈2\n",
    "review_list = []\n",
    "\n",
    "# 시작 페이지 지정\n",
    "page_num = 1\n",
    "\n",
    "while True:\n",
    "    # HTML 코드 받아오기\n",
    "    response = requests.get(\"https://movie.naver.com/movie/bi/mi/pointWriteFormList.naver?code=187323&type=after&isActualPointWriteExecute=false&isMileageSubscriptionAlready=false&isMileageSubscriptionReject=false&page=\" + str(page_num),headers = headers)\n",
    "\n",
    "    # BeautifulSoup 타입으로 변형하기\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    for i in range(10):\n",
    "        review = soup.find('span',{'id':f'_filtered_ment_{i}'})\n",
    "        review = review.get_text().strip()\n",
    "        review_list.append(review) \n",
    "    #print(str(page_num) + \"번째 페이지 가져오기 완료\")\n",
    "    page_num += 1\n",
    "\n",
    "    if page_num == 41:\n",
    "            break\n",
    "\n",
    "# DataFrame 만들기\n",
    "df4 = pd.DataFrame(data = review_list, columns = ['review'])\n",
    "df4['name'] = '베놈2'\n",
    "\n",
    "## 합치기\n",
    "df = pd.concat([df1,df2,df3,df4])\n",
    "print(len(df))\n",
    "df\n",
    "# df.to_csv('./movie_naver2.csv', header=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477c4266-6b37-48ad-a9a4-5351a938c86a",
   "metadata": {},
   "source": [
    "### 2.2 모델 학습 및 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dd2f1633-ff72-4da6-879d-773157434e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of samples: 1600\n",
      "Movie titles of reivews: {'듄', '보이스', '베놈2', '이터널스'}\n"
     ]
    }
   ],
   "source": [
    "text = []\n",
    "y = []\n",
    "with open('movie_naver2.csv', encoding='utf-8') as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    for row in csvreader:\n",
    "        #print(row)\n",
    "        if row: #그 줄에 내용이 있는 경우에만\n",
    "            text.append(row[1]) #영화 리뷰를 text 리스트에 추가\n",
    "            y.append(row[2]) #영화이름을 text 리스트에 추가\n",
    "\n",
    "print('Num of samples: {}'.format(len(text)))\n",
    "print('Movie titles of reivews: {}'.format(set(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dbb8db3d-4f35-4c5f-8425-4af3fcd8f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data and labels into a training and a test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, y, random_state=0)\n",
    "# 비율을 지정하지 않으면 75:25로 분할됨\n",
    "\n",
    "from konlpy.tag import Okt #konlpy에서 Twitter 형태소 분석기를 import\n",
    "#from konlpy.tag import Twitter #konlpy에서 Twitter 형태소 분석기를 import\n",
    "twitter_tag = Okt()\n",
    "#twitter_tag = Twitter()\n",
    "\n",
    "def twit_tokenizer2(text): #전체를 다 사용하는 대신, 명사, 동사, 형용사를 사용\n",
    "    target_tags = ['Noun', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in twitter_tag.pos(text, norm=True, stem=True):\n",
    "        if tag in target_tags:\n",
    "            result.append(word)\n",
    "#            result.append('/'.join([word, tag]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "542f93f0-173c-401f-9ec3-f9a20b74fd85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score 0.9175\n",
      "Test score 0.7225\n",
      "(1200, 1265)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer2, min_df=2) #명사, 동사, 형용사를 이용하여 tfidf 생성\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)\n",
    "# 현재까지 중에서 test score가 가장 뛰어남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3dcba823-aa8e-43bc-9d17-95b7d3405eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['듄' '보이스' '듄' '듄' '보이스' '이터널스' '듄' '보이스' '베놈2' '듄']\n"
     ]
    }
   ],
   "source": [
    "print(clf.predict(X_test_tfidf[:10])) # test data의 앞 10개에 대한 예측내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2ea74bfb-fdd0-4011-a90c-7494824c90db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['듄', '보이스', '베놈2', '듄', '듄', '이터널스', '듄', '이터널스', '베놈2', '보이스']\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:10]) # test data 앞 10개의 실제 영화제목"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1cb693-6a85-434e-98d5-135f58217dc9",
   "metadata": {},
   "source": [
    "|  | 정확도 | \n",
    "|--|--------|\n",
    "| Train score | **0.91** |\n",
    "| Test score | **0.72** |  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
